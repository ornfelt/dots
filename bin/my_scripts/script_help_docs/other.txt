find /home/www \( -type d -name .git -prune \) -o -type f -print0 | xargs -0 sed -i 's/subdomainA\.example\.com/subdomainB.example.com/g'

docker run --rm --interactive curlimages/curl curl \ --verbose --location --fail --silent --output - \ https://example.com

gcc -Wall main.c |& awk '/: warning:/{print "\x1B[01;31m" $0 "\x1B[m";next;}{print}' # Color gcc warnings in red 

journalctl --no-pager --since today \
--grep 'fail|error|fatal' --output json|jq '._EXE' | \
sort | uniq -c | sort --numeric --reverse --key 1

----------------------------------------------------------------------------------
Cut:
echo "This is a line of text" | cut -d ' ' -f5

With tr you can: echo "This is a line of text" | tr 'a' 'A'
> This is A line of text

echo "This is a line of text" | tr 'aeio' 'AEIO'
> ThIs Is A lInE Of tExt

echo "This is a line of text" | tr -d 'aeio'
> Ths s  ln f txt

echo "Thiis iis aaa liine   ooof  teeeeext" | tr -s 'aeio '
> This is a line of text

Some use /dev/urandom for generating passwords but head 3 /dev/urandom will have non utf-8 chars, then you can:
head 3 /dev/urandom | tr -cd '[:print:]'
-cd means complement delete

echo "This is a password: 1234" | tr -cd '[:digit:]'
> 1234

With sed you can also: echo "This is a line of text" | sed -e 'y/ai/AI/'
> ThIs Is A lInE Of text
but tr can do some more...

----------------------------------------------------------------------------------

df -a (print disk space usage in human readable format)

----------------------------------------------------------------------------------

select command in Linux is used to create a numbered menu from which a user can select an option.
Perl: It combines some of the best features of sed, awk, and sh, making it familiar and easy to use for Unix users to whip up quick solutions to annoying problems.
perl: https://www.computerhope.com/unix/uperl.htm#Options

df: the amount of space consumed by a particular file system on your LINUX system or how much space is available on a particular file system
Example: df kt.txt

tee command reads the standard input and writes it to both the standard output and one or more files. The command is named after the T-splitter used in plumbing. It basically breaks the output of a program so that it can be both displayed and saved in a file.

The uniq command in Linux is a command line utility that reports or filters out the repeated lines in a file. 
In simple words, uniq is the tool that helps to detect the adjacent duplicate lines and also deletes the duplicate lines:
uniq kt.txt

# -c – -count : It tells how many times a line was repeated by displaying a number as a prefix with the line.

cmp command in Linux/UNIX is used to compare the two files byte by byte and helps you to find out whether the two files are identical or not:
cmp file1.txt file2.txt
# -b(print-bytes) : If you want cmp displays the differing bytes in the output when used with -b option.
cmp -b file1.txt file2.tx

comm compare two sorted files line by line and write to standard output; the lines that are common and the lines that are unique.
comm file1.txt file2.txt

atrm command is used to remove the specified jobs. To remove a job, its job number is passed in the command. A user can only delete jobs that belong to him. Only superuser can delete any job even if that belongs to another user:
atrm 22
https://www.geeksforgeeks.org/atrm-command-in-linux-with-examples/?ref=rp

----------------------------------------------------------------------------------
wc stands for word count. As the name implies, it is mainly used for counting purpose.
It is used to find out number of lines, word count, byte and characters count in the files specified in the file arguments:
wc state.txt
wc state.txt capital.txt
# -l: This option prints the number of lines present in a file.
wc -l state.txt
# -w: This option prints the number of words present in a file. 
wc -w state.txt

# To count all files and folders present in directory:
ls gfg | wc -l

# Display number of word count only of a file:
$ wc -w  state.txt | cut -c1
7
      OR
$ wc -w < state.txt
7

----------------------------------------------------------------------------------
SORT command is used to sort a file, arranging the records in a particular order. By default, the sort command sorts file assuming the contents are ASCII. Using options in the sort command can also be used to sort numerically:
sort filename.txt
$ sort file.txt > output.txt 
$ sort -o output.txt file.txt
# -r Option: Sorting In Reverse Order: You can perform a reverse-order sort using the -r flag
# -n Option: To sort a file numerically used –n option.
# -k Option: Unix provides the feature of sorting a table on the basis of any column number by using -k option.
# -c option: This option is used to check if the file given is already sorted or not & checks if a file is already sorted pass the -c option to sort.
# -u option: To sort and remove duplicates pass the -u option to sort. This will write a sorted list to standard output and remove duplicates. 
# -M Option: To sort by month pass the -M option to sort. This will write a sorted list to standard output ordered by month name. 

----------------------------------------------------------------------------------
process substituion in Bash:
pr -mt <(ls -1v dir1) <(ls -1v dir2)

history
!1000 to run command 1000 from history
if you use ! before a command, it will use the same arguments as before
So if you have run ls -a before
then: !ls -> ls -a

----------------------------------------------------------------------------------
Vim:
I can easily take the document to a point 10 minutes back by using the command :
:earlier 10m
Or for that matter, move to a point 5 seconds ahead by using the command:
:later 5s
You can use the command :undolist to see a list of undo branches existing in the buffer. And each branch will have a number associated with it and it is possible to move to the undo level by using the command:
:undo

To undo all edits since opening file:
:e!

----------------------------------------------------------------------------------
Inspiration for find and replace from: https://stackoverflow.com/questions/1583219/how-to-do-a-recursive-find-replace-of-a-string-with-awk-or-sed

find /home/www/ -type f -exec \
    sed -i 's/subdomainA\.example\.com/subdomainB.example.com/g' {} +

sed -i '' -e 's/subdomainA/subdomainB/g' $(find /home/www/ -type f)

grep -rl oldtext . | xargs sed -i 's/oldtext/newtext/g'

find /home/www \( -type d -name .git -prune \) -o -type f -print0 | xargs -0 sed -i 's/subdomainA\.example\.com/subdomainB.example.com/g'

-print0 tells find to print each of the results separated by a null character, rather than a new line. In the unlikely event that your directory has files with newlines in the names, this still lets xargs work on the correct filenames.
\( -type d -name .git -prune \) is an expression which completely skips over all directories named .git. You could easily expand it, if you use SVN or have other folders you want to preserve -- just match against more names. It's roughly equivalent to -not -path .git, but more efficient, because rather than checking every file in the directory, it skips it entirely. The -o after it is required because of how -prune actually works.

----------------------------------------------------------------------------------
Xargs:
Xargs take standard input and pass it along into another command

Mostly from: https://www.youtube.com/watch?v=rp7jLi_kgPg
Xargs: output from command1 turns into arguments for command2: command1 | xargs command2
Examples:
seq 5

You can't:
seq 5 | echo
but you can:
seq 5 | xargs echo
or just the following, since xargs defaults to echo:
seq 5 | xargs

cat /etc/passwd (lists all users on your system)
clean this up via:
cut -d: -f1 < /etc/passwd | sort | xargs
The above command will cut with the delimiter ":", grabs the first field of each line (-f1), sort it alphabetically and then echo with xargs

-I flag Makes it so that you can use placeholder for the output of the ls command, below {} will be placeholders:
ls | xargs -I {} echo "/home/jonas/{}"
The above basically prints the pwd for the files / directories if you are in the user folder. You can use anything as placeholders

Create 1000 files called 1.txt -> 1000.txt
seq 1000 | xargs -I {} touch {}.txt

To change name: ls | cut -d. -f1 | xargs -I {} mv {}.txt {}.text

Delete all .text files in the directory: rm *.text

ls | xargs -t

Specify max number of arguments
ls | xargs -t -n 1
Below will take one argument and one process at a time and sleep in between. -P is the max number of processes
seq 5 | xargs -n 1 -P 1 bash -c 'echo $0; sleep 1'

Xargs is commonly used with find, since it is better than exec:
If you are in home folder and have a folder named foo then:
find foo -type f -name "*.text" -exec rm {} \;
Xargs version:
find foo -type f -name "*.text" | xargs rm
Or if you are in the directory foo
find . -type f -name "*.text" | xargs rm

Time difference between exec and xargs:
time find foo -type f -name "*.text" -exec rm {} \;
Xargs version:
time find foo -type f -name "*.text" | xargs rm
xargs about 6-7 times faster.

------------

The -t option prints each command that will be executed to the terminal. This can be helpful when debugging scripts.
echo 'one two three' | xargs -t rm
rm one two three

The -p command will print the command to be executed and prompt the user to run it
echo 'one two three' | xargs -p touch
touch one two three ?...

Run multiple commands with xarg:
cat foo.txt
one
two
three

cat foo.txt | xargs -I % sh -c 'echo %; mkdir %'
one 
two
three

ls 
one two three

****************************
Xargs and | difference

When you use piping without xargs , the actual data is fed into the next command:
| named pipeline. It pipe previous program's stdout to next program's stdin.
xargs read from stdin every line, and execute command which specified from args(when "xargs -n 1").

Xargs basically same as -exec but xargs is much faster:
find ./foo -type f -name "*.txt" -exec rm {} \; 
find ./foo -type f -name "*.txt" | xargs rm

echo file1 file2 | cat    # Prints "file1 file2", since that's the stream of
                          # bytes that echo passed to cat's STDIN
cat file1 file2    # Prints the CONTENTS of file1 and file2
echo file1 file2 | rm    # Prints an error message, since rm expects arguments
                         # and doesn't read from STDIN
						 
xargs can be thought of as converting STDIN-style input to arguments:
echo file1 file2 | cat    # Prints "file1 file2"
echo file1 file2 | xargs cat    # Prints the CONTENTS of file1 and file2

*** Pipe is used to connect between two command
*** Xargs redirect the output of second command to the first one

----------------------------------------------------------------------------------
In the command-line, you can press alt + . or esc - . It cycles through the last argument of your previous commands.

!$ is a word designator of history expansion, it expands to the last word of previous command in history:
the whole command 'echo "hello" > /tmp/a.txt' appeared in history, and /tmp/a.txt is the last word of that command.

_ is a shell parameter, it expands to last argument of previous command. Here, the redirection is not a part of arguments passed to the command, so only hello is the argument passed to echo. That's why $_ expanded to hello.

$ echo 1 && echo $_
1
/usr/bin/ksh

$ echo 1
1
$ echo $_
1

----------------------------------------------------------------------------------
mpv --start=45:00 'https://www.youtube.com/watch?v=<video-id>'

split .bashrc into files containing 100 lines each
split -l 100 .bashrc

Git advanced techniques and shortcuts: https://www.youtube.com/watch?v=ecK3EnyGD8o
Git add . and commit: git commit -am "that was easy!"
Change last commit message: Git commit --ammend -m "nice!"
Pretty logs: git log --graph --oneline --decorate

----------------------------------------------------------------------------------
RASPBERRY PI LCD:
Turn on lcd:
sudo rm -rf LCD-show 
git clone https://github.com/goodtft/LCD-show.git 
chmod -R 755 LCD-show 
cd LCD-show/
sudo ./LCD35-show
Switch led off:
chmod -R 755 LCD-show 
cd LCD-show/ 
sudo ./LCD-hdmi

----------------------------------------------------------------------------------
sed '$!N; /^\(.*\)\n\1$/!P; D' ostechnix.txt # Delete duplicate lines in files

# Display Arch Linux news on Terminal
w3m https://www.archlinux.org/ | sed -n "/Latest News/,/Older News/p" | head -n -1 

find . -name '*.pdf' | xargs rm -v # Find and delete specific type of files

watch grep \"cpu MHz\" /proc/cpuinfo # Monitor CPU speed

cut -d ':' -f 1,3 /etc/passwd | sort -t ':' -k2n - | tr ':' '\t' # Display Username and UID

tr -c a-zA-Z '\n' < Readme1.txt  | sed '/^$/d' | sort | uniq -i -c # List unique words

sort m1.txt | join - m2.txt # Join unsorted file with a sorted file

ps aux | awk '{if ($5 != 0 ) print $2,$5,$6,$11}' | sort -k2n # check process usage

du -sk /var/log/* | sort -r -n | head -10 # Top 10 Largest File / Dirs

# Find out Top 10 Most Used Commands
cat ~/.bash_history | tr "\|\;" "\n" | sed -e "s/^ //g" | cut -d " " -f 1 | sort | uniq -c | sort -n | tail -n 15


cd - (Change to the previous working directory)
Run the previous shell command but replace string "foo" with "bar"
$ ^foo^bar^

sed -i 's#ORIGINAL_VALLUE#NEW_VALUE#g' myfile1 myfile2
perl -p -i -e 's#ORIGINAL#NEW_VALUE#' myfile1 myfile2

cd $mydir && python3 -m http.server 8888 # Share a file quickly using a web server

#Find failures with journalctl
journalctl --no-pager --since today \
--grep 'fail|error|fatal' --output json|jq '._EXE' | \
sort | uniq -c | sort --numeric --reverse --key 1

Search for a file
grep -R 'import' --include='*.java' --color MySourceCodeDir
find MySourceCodeDir/ -name '*.java' -type f -print| xargs \
grep --color 'import

Update all Git repositories on a directory
for i in */.git; do cd $(dirname $i); git pull; cd ..; done

Convert a CSV to JSON
python3 -c \
"import csv,json,sys;print(json.dumps(list(csv.reader(open(sys.argv[1])))))" \
covid19-vaccinations-town-age-grp.csv

Install and run commands with Docker
docker run --rm --interactive curlimages/curl curl \
--verbose --location --fail --silent --output - \
https://example.com

mtr - traceroute and ping combined
$ mtr google.com

Find the last command that begins with "whatever," but avoid running it
$ !whatever:p

Search for a matching command previously typed in BASH
$Ctrl-R <search-text>

Find all files larger than 5M and less than 10M
Useful, for example, to search for a log file of a specific size.
$find / -type f -size +50M -size -10M

You can simulate typing on the screen and look like a hacker by controlling the speed at which you type.
$echo "Lorem ipsum dolor sit amet, consectetuer adipiscing elit." | pv -qL 20

Note: you need to have installed the< pv> utility used to monitor data progress through a pipe.
$sudo apt install pv

Show working directory of a process
$pwdx pid
(find pid via: $ ps ax | grep firefox / $ pidof firefox)

Set password protection to a file using vim
$vim -x file.txt

Monitor memory usage in a human-readable way
watch vmstat -sSM

Enter the matrix
$perl -e '$|++; while (1) { print " ." x (rand(10) + 1), int(rand(2)) }'

----------------------------------------------------------------------------------
WINDOWS:
cmd as admin
sfc /scannow
check for damaged system files and automatically repair
If it fails to repair, restart computer and try:
DISM /Online /Cleanup-Image /RestoreHealth then restart and run asfc /scannow again

Check for disk errors ( /r will check for bad sectors)
chkdsk C: /r

List tasks, similar to task manager
tasklist 

taskkill
taskkill /f /t /im notepad.exe OR taskkill /f /t /pid 23136

powercfg /energy (generate error report file related to system power)
powercfg /batteryreport


----------------------------------------------------------------------------------
script_copy:

sed -i 's/ORIGINAL_VALLUE/NEW_VALUE/g' myfile1 myfile2 OR perl -p -i -e 's/ORIGINAL/NEW_VALUE/' myfile1 myfile2

watch vmstat -sSM # Monitor memory

watch grep \"cpu MHz\" /proc/cpuinfo # Monitor CPU speed

ps aux | awk '{if ($5 != 0 ) print $2,$5,$6,$11}' | sort -k2n # check process usage

echo "Lorem ipsum dolor sit amet, consectetuer adipiscing elit." | pv -qL 20

perl -e '$|++; while (1) { print " ." x (rand(10) + 1), int(rand(2)) }'

w3m https://www.archlinux.org/ | sed -n "/Latest News/,/Older News/p" | head -n -1 

git grep -l 'original_text' | xargs sed -i 's/original_text/new_text/g'

for i in */.git; do cd $(dirname $i); git pull; cd ..; done

awk '!/regexp/' # Print non matching lines (egrep -v regexp): 

awk '/^[ ... # This prints all lines except empty ones and lines with only space and tab: 

awk 'length($0)>80{print FNR,$0}'  file.txt # Find all the lines longer than 80 characters (or any other length): 

awk 'length < 80' file.txt # Print lines with < 80 char

cd $mydir && python3 -m http.server 8888 # Share a file quickly using a web server

python3 -c  'import csv ...

cat ~/.bash_history ...

mtr google.com

^foo^bar^ # Run the previous shell command but replace string "foo" with "bar"

!whatever:p # Find last command beginning with whatever

Ctrl-R <search-text>

journalctl --disk-usage

sudo journalctl --vacuum-size=500M

du -sh -- *  | sort -rh  # Files and directories, or

du -sh -- */ | sort -rh  # Directories only

find / -type f -size +50M -size -10M # Find files > 5M and < 10M

du -sk /var/log/* | sort -r -n | head -10 # Top 10 Largest File / Dirs

grep -R 'import' --include='*.java' --color MySourceCodeDir # Search for file

find MySourceCodeDir/ -name ... 

find . -name '*.pdf' | xargs rm -v # Find and delete specific type of files
